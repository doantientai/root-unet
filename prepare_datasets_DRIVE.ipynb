{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==========================================================\n",
    "#\n",
    "#  This prepare the hdf5 datasets of the DRIVE database\n",
    "#\n",
    "#============================================================\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def write_hdf5(arr,outfile):\n",
    "    with h5py.File(outfile,\"w\") as f:\n",
    "        f.create_dataset(\"image\", data=arr, dtype=arr.dtype)\n",
    "\n",
    "\n",
    "#------------Path of the images --------------------------------------------------------------\n",
    "#train\n",
    "original_imgs_train = \"./Data/RootsPairs_r/imgs//\"\n",
    "groundTruth_imgs_train = \"./DRIVE/training/groundTruth/\"\n",
    "#borderMasks_imgs_train = \"./DRIVE/training/mask/\"\n",
    "#test\n",
    "original_imgs_test = \"./DRIVE/test/imgs/\"\n",
    "groundTruth_imgs_test = \"./DRIVE/test/groundTruth/\"\n",
    "#borderMasks_imgs_test = \"./DRIVE/test/mask/\"\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "Nimgs = 14\n",
    "channels = 3\n",
    "height = 584\n",
    "width = 565\n",
    "dataset_path = \"./DRIVE_datasets_training_testing/\"\n",
    "\n",
    "def get_datasets(imgs_dir,groundTruth_dir,train_test=\"null\"):\n",
    "    imgs = np.empty((Nimgs,height,width,channels))\n",
    "    groundTruth = np.empty((Nimgs,height,width))\n",
    "    #border_masks = np.empty((Nimgs,height,width))\n",
    "    for path, subdirs, files in os.walk(imgs_dir): #list all files, directories in the path\n",
    "        for i in range(len(files)):\n",
    "            #original\n",
    "            print \"original image: \" +files[i]\n",
    "            img = Image.open(imgs_dir+files[i])\n",
    "            imgs[i] = np.asarray(img)\n",
    "            #corresponding ground truth\n",
    "            groundTruth_name = files[i][0:2] + \"_manual1.gif\"\n",
    "            print \"ground truth name: \" + groundTruth_name\n",
    "            g_truth = Image.open(groundTruth_dir + groundTruth_name)\n",
    "            groundTruth[i] = np.asarray(g_truth)\n",
    "            #corresponding border masks\n",
    "            #border_masks_name = \"\"\n",
    "            #if train_test==\"train\":\n",
    "            #    border_masks_name = files[i][0:2] + \"_training_mask.gif\"\n",
    "            #elif train_test==\"test\":\n",
    "            #    border_masks_name = files[i][0:2] + \"_test_mask.gif\"\n",
    "            #else:\n",
    "            #    print \"specify if train or test!!\"\n",
    "            #    exit()\n",
    "            #print \"border masks name: \" + border_masks_name\n",
    "            #b_mask = Image.open(borderMasks_dir + border_masks_name)\n",
    "            #border_masks[i] = np.asarray(b_mask)\n",
    "\n",
    "    print \"imgs max: \" +str(np.max(imgs))\n",
    "    print \"imgs min: \" +str(np.min(imgs))\n",
    "    #assert(np.max(groundTruth)==255 and np.max(border_masks)==255)\n",
    "    #assert(np.min(groundTruth)==0 and np.min(border_masks)==0)\n",
    "    #print \"ground truth and border masks are correctly withih pixel value range 0-255 (black-white)\"\n",
    "    #reshaping for my standard tensors\n",
    "    imgs = np.transpose(imgs,(0,3,1,2))\n",
    "    assert(imgs.shape == (Nimgs,channels,height,width))\n",
    "    groundTruth = np.reshape(groundTruth,(Nimgs,1,height,width))\n",
    "    #border_masks = np.reshape(border_masks,(Nimgs,1,height,width))\n",
    "    assert(groundTruth.shape == (Nimgs,1,height,width))\n",
    "    #assert(border_masks.shape == (Nimgs,1,height,width))\n",
    "    return imgs, groundTruth\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "#getting the training datasets\n",
    "imgs_train, groundTruth_train = get_datasets(original_imgs_train,groundTruth_imgs_train,\"train\")\n",
    "print \"saving train datasets\"\n",
    "write_hdf5(imgs_train, dataset_path + \"DRIVE_dataset_imgs_train.hdf5\")\n",
    "write_hdf5(groundTruth_train, dataset_path + \"DRIVE_dataset_groundTruth_train.hdf5\")\n",
    "#write_hdf5(border_masks_train,dataset_path + \"DRIVE_dataset_borderMasks_train.hdf5\")\n",
    "\n",
    "#getting the testing datasets\n",
    "imgs_test, groundTruth_test = get_datasets(original_imgs_test,groundTruth_imgs_test,\"test\")\n",
    "print \"saving test datasets\"\n",
    "write_hdf5(imgs_test,dataset_path + \"DRIVE_dataset_imgs_test.hdf5\")\n",
    "write_hdf5(groundTruth_test, dataset_path + \"DRIVE_dataset_groundTruth_test.hdf5\")\n",
    "#write_hdf5(border_masks_test,dataset_path + \"DRIVE_dataset_borderMasks_test.hdf5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
