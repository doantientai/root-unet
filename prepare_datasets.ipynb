{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image: T32_W01_H02.JPG\n",
      "ground truth name: T32_W01_H02.JPG\n",
      "original image: 26_4_12_TB3_00_30.jpg\n",
      "ground truth name: 26_4_12_TB3_00_30.jpg\n",
      "original image: T23_W01_H02.JPG\n",
      "ground truth name: T23_W01_H02.JPG\n",
      "original image: T09_W01_H02.JPG\n",
      "ground truth name: T09_W01_H02.JPG\n",
      "original image: T26_W01_H02.JPG\n",
      "ground truth name: T26_W01_H02.JPG\n",
      "original image: T31_W01_H02.JPG\n",
      "ground truth name: T31_W01_H02.JPG\n",
      "original image: T11_W01_H02.JPG\n",
      "ground truth name: T11_W01_H02.JPG\n",
      "original image: T05_W01_H02.JPG\n",
      "ground truth name: T05_W01_H02.JPG\n",
      "original image: T12_W01_H02.JPG\n",
      "ground truth name: T12_W01_H02.JPG\n",
      "original image: T29_W01_H02.JPG\n",
      "ground truth name: T29_W01_H02.JPG\n",
      "original image: T07_W01_H02.JPG\n",
      "ground truth name: T07_W01_H02.JPG\n",
      "original image: 26_4_12_TB4.jpg\n",
      "ground truth name: 26_4_12_TB4.jpg\n",
      "original image: T25_W01_H02.JPG\n",
      "ground truth name: T25_W01_H02.JPG\n",
      "original image: 26_4_12_TB7.jpg\n",
      "ground truth name: 26_4_12_TB7.jpg\n",
      "original image: 26_4_12_TB2_60_90.jpg\n",
      "ground truth name: 26_4_12_TB2_60_90.jpg\n",
      "original image: T20_W01_H02.JPG\n",
      "ground truth name: T20_W01_H02.JPG\n",
      "original image: T06_W01_H02.JPG\n",
      "ground truth name: T06_W01_H02.JPG\n",
      "original image: T15_W01_H02.JPG\n",
      "ground truth name: T15_W01_H02.JPG\n",
      "original image: 26_4_12_TB8.jpg\n",
      "ground truth name: 26_4_12_TB8.jpg\n",
      "original image: T28_W01_H02.JPG\n",
      "ground truth name: T28_W01_H02.JPG\n",
      "original image: 26_4_12_TW1.jpg\n",
      "ground truth name: 26_4_12_TW1.jpg\n",
      "original image: 26_4_12_TB1_60_90.jpg\n",
      "ground truth name: 26_4_12_TB1_60_90.jpg\n",
      "original image: T10_W01_H02.JPG\n",
      "ground truth name: T10_W01_H02.JPG\n",
      "original image: 26_4_12_TB3_60_90.jpg\n",
      "ground truth name: 26_4_12_TB3_60_90.jpg\n",
      "original image: T13_W01_H02.JPG\n",
      "ground truth name: T13_W01_H02.JPG\n",
      "original image: T24_W01_H02.JPG\n",
      "ground truth name: T24_W01_H02.JPG\n",
      "original image: T17_W01_H02.JPG\n",
      "ground truth name: T17_W01_H02.JPG\n",
      "original image: T19_W01_H02.JPG\n",
      "ground truth name: T19_W01_H02.JPG\n",
      "original image: T27_W01_H02.JPG\n",
      "ground truth name: T27_W01_H02.JPG\n",
      "original image: 26_4_12_TB5.jpg\n",
      "ground truth name: 26_4_12_TB5.jpg\n",
      "original image: 26_4_12_TB6.jpg\n",
      "ground truth name: 26_4_12_TB6.jpg\n",
      "original image: 26_4_12_TB9.jpg\n",
      "ground truth name: 26_4_12_TB9.jpg\n",
      "imgs max: 255.0\n",
      "imgs min: 0.0\n",
      "saving train datasets\n",
      "(32, 3, 1860, 1328)\n",
      "original image: T21_W01_H02.JPG\n",
      "ground truth name: T21_W01_H02.JPG\n",
      "original image: T16_W01_H02.JPG\n",
      "ground truth name: T16_W01_H02.JPG\n",
      "original image: T08_W01_H02.JPG\n",
      "ground truth name: T08_W01_H02.JPG\n",
      "original image: T30_W01_H02.JPG\n",
      "ground truth name: T30_W01_H02.JPG\n",
      "imgs max: 255.0\n",
      "imgs min: 0.0\n",
      "saving test datasets\n",
      "(4, 3, 1860, 1328)\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "#==========================================================\n",
    "#\n",
    "#  This prepare the hdf5 datasets of the DRIVE database\n",
    "#\n",
    "#============================================================\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "def write_hdf5(arr,outfile):\n",
    "    with h5py.File(outfile,\"w\") as f:\n",
    "        f.create_dataset(\"image\", data=arr, dtype=arr.dtype)\n",
    "\n",
    "\n",
    "#------------Path of the images --------------------------------------------------------------\n",
    "#train\n",
    "PATH_TO_FOLD = \"./Data/datasets/RootsPairs-data1-2/data_1n2_r/folds/fold-1/\"\n",
    "original_imgs_train = PATH_TO_FOLD + \"train/imgs/\"\n",
    "groundTruth_imgs_train = PATH_TO_FOLD + \"train/groundTruth/\"\n",
    "#borderMasks_imgs_train = \"./DRIVE/training/mask/\"\n",
    "#test\n",
    "original_imgs_test = PATH_TO_FOLD + \"test/imgs/\"\n",
    "groundTruth_imgs_test = PATH_TO_FOLD + \"test/groundTruth/\"\n",
    "#borderMasks_imgs_test = \"./DRIVE/test/mask/\"\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "# Nimgs = len([f for f in listdir(original_imgs_train) if isfile(join(original_imgs_train, f))])\n",
    "\n",
    "# Nimgs = 14\n",
    "channels = 3\n",
    "# height = 1661\n",
    "# width = 2325\n",
    "\n",
    "height = 1860\n",
    "width = 1328\n",
    "\n",
    "\n",
    "\n",
    "dataset_path = \"./Data/OnDuty/\"\n",
    "\n",
    "def get_datasets(imgs_dir,groundTruth_dir,train_test=\"null\"):\n",
    "    \n",
    "    Nimgs = len([f for f in listdir(imgs_dir) if isfile(join(imgs_dir, f))])\n",
    "    imgs = np.empty((Nimgs,height,width,channels))\n",
    "    groundTruth = np.empty((Nimgs,height,width))\n",
    "    #border_masks = np.empty((Nimgs,height,width))\n",
    "    for path, subdirs, files in os.walk(imgs_dir): #list all files, directories in the path\n",
    "        for i in range(len(files)):\n",
    "            #original\n",
    "            print (\"original image: \" +files[i])\n",
    "            img = Image.open(imgs_dir+files[i])\n",
    "#             print(np.shape(img))\n",
    "            imgs[i] = np.asarray(img)\n",
    "            #corresponding ground truth\n",
    "#             groundTruth_name = files[i][0:2] + \"_manual1.gif\"\n",
    "#             groundTruth_name = files[i][0:len(files[i])-8] + \".jpg\"\n",
    "            groundTruth_name = files[i]\n",
    "            print (\"ground truth name: \" + groundTruth_name)\n",
    "            g_truth = Image.open(groundTruth_dir + groundTruth_name).convert('L')\n",
    "#             print(np.shape(g_truth))\n",
    "            groundTruth[i] = np.asarray(g_truth)\n",
    "            #corresponding border masks\n",
    "            #border_masks_name = \"\"\n",
    "            #if train_test==\"train\":\n",
    "            #    border_masks_name = files[i][0:2] + \"_training_mask.gif\"\n",
    "            #elif train_test==\"test\":\n",
    "            #    border_masks_name = files[i][0:2] + \"_test_mask.gif\"\n",
    "            #else:\n",
    "            #    print \"specify if train or test!!\"\n",
    "            #    exit()\n",
    "            #print \"border masks name: \" + border_masks_name\n",
    "            #b_mask = Image.open(borderMasks_dir + border_masks_name)\n",
    "            #border_masks[i] = np.asarray(b_mask)\n",
    "\n",
    "    print (\"imgs max: \" +str(np.max(imgs)))\n",
    "    print (\"imgs min: \" +str(np.min(imgs)))\n",
    "    #assert(np.max(groundTruth)==255 and np.max(border_masks)==255)\n",
    "    #assert(np.min(groundTruth)==0 and np.min(border_masks)==0)\n",
    "    #print \"ground truth and border masks are correctly withih pixel value range 0-255 (black-white)\"\n",
    "    #reshaping for my standard tensors\n",
    "    imgs = np.transpose(imgs,(0,3,1,2))\n",
    "    assert(imgs.shape == (Nimgs,channels,height,width))\n",
    "    groundTruth = np.reshape(groundTruth,(Nimgs,1,height,width))\n",
    "    #border_masks = np.reshape(border_masks,(Nimgs,1,height,width))\n",
    "    assert(groundTruth.shape == (Nimgs,1,height,width))\n",
    "    #assert(border_masks.shape == (Nimgs,1,height,width))\n",
    "    return imgs, groundTruth\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "#getting the training datasets\n",
    "imgs_train, groundTruth_train = get_datasets(original_imgs_train,groundTruth_imgs_train,\"train\")\n",
    "print (\"saving train datasets\")\n",
    "print(imgs_train.shape)\n",
    "write_hdf5(imgs_train, dataset_path + \"DRIVE_dataset_imgs_train.hdf5\")\n",
    "write_hdf5(groundTruth_train, dataset_path + \"DRIVE_dataset_groundTruth_train.hdf5\")\n",
    "#write_hdf5(border_masks_train,dataset_path + \"DRIVE_dataset_borderMasks_train.hdf5\")\n",
    "\n",
    "#getting the testing datasets\n",
    "imgs_test, groundTruth_test = get_datasets(original_imgs_test,groundTruth_imgs_test,\"test\")\n",
    "print (\"saving test datasets\")\n",
    "print(imgs_test.shape)\n",
    "write_hdf5(imgs_test,dataset_path + \"DRIVE_dataset_imgs_test.hdf5\")\n",
    "write_hdf5(groundTruth_test, dataset_path + \"DRIVE_dataset_groundTruth_test.hdf5\")\n",
    "#write_hdf5(border_masks_test,dataset_path + \"DRIVE_dataset_borderMasks_test.hdf5\")\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Nimgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9b2a7a46c0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNimgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Nimgs' is not defined"
     ]
    }
   ],
   "source": [
    "Nimgs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
