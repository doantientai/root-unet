Using Theano backend.
WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:
 https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29

Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)
('train_imgs: ', (12, 3, 1661, 2325))
imgs_std:
32.7681903164
imgs_mean:
47.403771015
imgs:
(12, 3, 1661, 2325)
Passed!
('imgs.shape: ', (12, 3, 1661, 2325))
('imgs_equalized.shape: ', (12, 3, 1661, 2325))

train images/masks shape:
(12, 3, 1329, 2325)
train images range (min-max): 0.0 - 1.0
train masks are within 0-1

patches per full image: 1000

train PATCHES images/masks shape:
(12000, 3, 64, 64)
train PATCHES images range (min-max): 0.0 - 1.0
./src/retinaNN_training.py:121: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Elemwise{t..., inputs=/input_1)`
  model = Model(input=inputs, output=conv7)
Check: final output of the network:
(None, 4096, 2)
./src/retinaNN_training.py:256: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  model.fit(patches_imgs_train, patches_masks_train, nb_epoch=N_epochs, batch_size=batch_size, verbose=2, shuffle=True, validation_split=0.1, callbacks=[checkpointer])
Train on 10800 samples, validate on 1200 samples
Epoch 1/100
Epoch 00000: val_loss improved from inf to 0.00445, saving model to Experiments/root_64_rgb_weighted_categorical_crossentropy_025_1/root_64_rgb_weighted_categorical_crossentropy_025_1_best_weights.h5
90s - loss: 0.0406 - val_loss: 0.0045
Epoch 2/100
Epoch 00001: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 3/100
Epoch 00002: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 4/100
Epoch 00003: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 5/100
Epoch 00004: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 6/100
Epoch 00005: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 7/100
Epoch 00006: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 8/100
Epoch 00007: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 9/100
Epoch 00008: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 10/100
Epoch 00009: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 11/100
Epoch 00010: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 12/100
Epoch 00011: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 13/100
Epoch 00012: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 14/100
Epoch 00013: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 15/100
Epoch 00014: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 16/100
Epoch 00015: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 17/100
Epoch 00016: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 18/100
Epoch 00017: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 19/100
Epoch 00018: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 20/100
Epoch 00019: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 21/100
Epoch 00020: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 22/100
Epoch 00021: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 23/100
Epoch 00022: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 24/100
Epoch 00023: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 25/100
Epoch 00024: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 26/100
Epoch 00025: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 27/100
Epoch 00026: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 28/100
Epoch 00027: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 29/100
Epoch 00028: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 30/100
Epoch 00029: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 31/100
Epoch 00030: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 32/100
Epoch 00031: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 33/100
Epoch 00032: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 34/100
Epoch 00033: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 35/100
Epoch 00034: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 36/100
Epoch 00035: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 37/100
Epoch 00036: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 38/100
Epoch 00037: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 39/100
Epoch 00038: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 40/100
Epoch 00039: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 41/100
Epoch 00040: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 42/100
Epoch 00041: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 43/100
Epoch 00042: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 44/100
Epoch 00043: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 45/100
Epoch 00044: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 46/100
Epoch 00045: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 47/100
Epoch 00046: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 48/100
Epoch 00047: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 49/100
Epoch 00048: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 50/100
Epoch 00049: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 51/100
Epoch 00050: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 52/100
Epoch 00051: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 53/100
Epoch 00052: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 54/100
Epoch 00053: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 55/100
Epoch 00054: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 56/100
Epoch 00055: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 57/100
Epoch 00056: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 58/100
Epoch 00057: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 59/100
Epoch 00058: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 60/100
Epoch 00059: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 61/100
Epoch 00060: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 62/100
Epoch 00061: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 63/100
Epoch 00062: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 64/100
Epoch 00063: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 65/100
Epoch 00064: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 66/100
Epoch 00065: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 67/100
Epoch 00066: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 68/100
Epoch 00067: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 69/100
Epoch 00068: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 70/100
Epoch 00069: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 71/100
Epoch 00070: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 72/100
Epoch 00071: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 73/100
Epoch 00072: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 74/100
Epoch 00073: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 75/100
Epoch 00074: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 76/100
Epoch 00075: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 77/100
Epoch 00076: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 78/100
Epoch 00077: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 79/100
Epoch 00078: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 80/100
Epoch 00079: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 81/100
Epoch 00080: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 82/100
Epoch 00081: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 83/100
Epoch 00082: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 84/100
Epoch 00083: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 85/100
Epoch 00084: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 86/100
Epoch 00085: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 87/100
Epoch 00086: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 88/100
Epoch 00087: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 89/100
Epoch 00088: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 90/100
Epoch 00089: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 91/100
Epoch 00090: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 92/100
Epoch 00091: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 93/100
Epoch 00092: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 94/100
Epoch 00093: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 95/100
Epoch 00094: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 96/100
Epoch 00095: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 97/100
Epoch 00096: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 98/100
Epoch 00097: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 99/100
Epoch 00098: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
Epoch 100/100
Epoch 00099: val_loss did not improve
89s - loss: 0.0148 - val_loss: 0.0045
